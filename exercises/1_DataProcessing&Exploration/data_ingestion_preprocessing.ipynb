{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2b1218-f752-4e49-b0f6-95f2ac8b8323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Ingestion, Processing, and MLflow Model Logging\n",
    "import io, os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "from domino.data_sources import DataSourceClient\n",
    "from domino_data.datasets import DatasetClient\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "import time\n",
    "import yaml\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "domino_working_dir = os.environ.get(\"DOMINO_WORKING_DIR\", \".\")\n",
    "domino_datasource_dir = domino_working_dir.replace('code', 'data')\n",
    "domino_artifact_dir = domino_working_dir.replace('code', 'artifacts')\n",
    "domino_project_name = os.environ.get(\"DOMINO_PROJECT_NAME\", \"my-local-project\")\n",
    "\n",
    "## Data Ingestion, Processing, and MLflow Model Logging\n",
    "\n",
    "def run_data_ingestion_and_processing(raw_filename: str, pca_filename: str, n_components: int = 8):\n",
    "    # 1) Download the raw file\n",
    "    ds = DataSourceClient().get_datasource(\"credit_card_fraud_detection\")\n",
    "    buf = io.BytesIO()\n",
    "    ds.download_fileobj(raw_filename, buf)\n",
    "    buf.seek(0)\n",
    "    df = pd.read_csv(buf)\n",
    "    print(f\"ðŸ” Loaded {len(df):,} rows from {raw_filename}\")\n",
    "\n",
    "    # 2) Drop missing rows\n",
    "    before = len(df)\n",
    "    df = df.dropna()\n",
    "    after = len(df)\n",
    "    pct_removed = 100 * (before - after) / before if before > 0 else 0\n",
    "    print(f\"ðŸ§¹ Dropped {before - after:,} rows with missing data\")\n",
    "\n",
    "    # 3) Define columns\n",
    "    cat_cols = [\"TxType\", \"DeviceType\", \"MerchantCat\", \"Channel\", \"CardPresent\"]\n",
    "    num_cols = [\n",
    "        \"Amount\", \"Age\", \"Tenure\", \"MerchantRisk\", \"DeviceTrust\",\n",
    "        \"Txn24h\", \"Avg30d\", \"IPReputation\", \"Latitude\", \"Longitude\", \"DistFromHome\"\n",
    "    ]\n",
    "    X = df[cat_cols + num_cols]\n",
    "    y = df[\"Class\"]\n",
    "\n",
    "    # 4) Build and fit Pipeline: OHE categoricals, scale numerics, then PCA on all\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"ohe\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"), cat_cols),\n",
    "            (\"scale\", StandardScaler(), num_cols)\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "    pipeline = Pipeline([\n",
    "        (\"preproc\", preprocessor),\n",
    "        (\"pca\",     PCA(n_components=n_components, random_state=0))\n",
    "    ])\n",
    "    start_time = time.time()\n",
    "    PCs = pipeline.fit_transform(X)\n",
    "    fit_time = time.time() - start_time\n",
    "    pca_model = pipeline.named_steps[\"pca\"]\n",
    "\n",
    "    # 5) Reassemble and save PCA DataFrame\n",
    "    pca_df = pd.DataFrame(PCs, columns=[f\"V{i+1}\" for i in range(n_components)])\n",
    "    pca_df[\"Time\"]   = df[\"Time\"].astype(int)\n",
    "    pca_df[\"Amount\"] = df[\"Amount\"]\n",
    "    pca_df[\"Class\"]  = df[\"Class\"].astype(int)\n",
    "\n",
    "    full_path = f\"{domino_datasource_dir}/{domino_project_name}/{pca_filename}\"\n",
    "    pca_df.to_csv(full_path, index=False)\n",
    "    print(f\"âœ… Wrote {len(pca_df):,} rows to: {pca_filename}\")\n",
    "\n",
    "    # 6) Start MLflow run and log everything\n",
    "    mlflow.set_experiment('CC Fraud PCA Training [testing]')\n",
    "    with mlflow.start_run(run_name=\"PCA Pipeline\") as run:\n",
    "        # Log parameters\n",
    "        mlflow.log_param(\"n_components\", n_components)\n",
    "        mlflow.log_param(\"raw_filename\", raw_filename)\n",
    "        mlflow.log_param(\"pca_filename\", pca_filename)\n",
    "        mlflow.log_param(\"num_rows_loaded\", before)\n",
    "        mlflow.log_param(\"num_rows_after_dropna\", after)\n",
    "        mlflow.log_param(\"num_cat_features\", len(cat_cols))\n",
    "        mlflow.log_param(\"num_num_features\", len(num_cols))\n",
    "\n",
    "        # Log human-readable pipeline parameters as YAML\n",
    "        pipeline_params = {\n",
    "            \"n_components\": n_components,\n",
    "            \"raw_filename\": raw_filename,\n",
    "            \"pca_filename\": pca_filename,\n",
    "            \"num_rows_loaded\": before,\n",
    "            \"num_rows_after_dropna\": after,\n",
    "            \"num_cat_features\": len(cat_cols),\n",
    "            \"num_num_features\": len(num_cols),\n",
    "            \"categorical_columns\": cat_cols,\n",
    "            \"numerical_columns\": num_cols,\n",
    "        }\n",
    "        params_yaml_path = f\"{domino_artifact_dir}/pipeline_params.yaml\"\n",
    "        with open(params_yaml_path, \"w\") as f:\n",
    "            yaml.dump(pipeline_params, f, default_flow_style=False)\n",
    "        mlflow.log_artifact(params_yaml_path, artifact_path=\"params\")\n",
    "\n",
    "        # Log the PCA CSV\n",
    "        mlflow.log_artifact(full_path, artifact_path=\"data\")\n",
    "\n",
    "        # Log the pipeline as a single model\n",
    "        X_sig = X.copy()\n",
    "        for col in num_cols:\n",
    "            if np.issubdtype(X_sig[col].dtype, np.integer):\n",
    "                X_sig[col] = X_sig[col].astype(\"float64\")\n",
    "        signature = infer_signature(X_sig.iloc[:5], pipeline.transform(X_sig.iloc[:5]))\n",
    "        mlflow.sklearn.log_model(\n",
    "            pipeline,\n",
    "            artifact_path=\"preproc_pca_pipeline\",\n",
    "            registered_model_name=\"CC Fraud Preprocessing & PCA\",\n",
    "            signature=signature\n",
    "        )\n",
    "        mlflow.set_tag(\"pipeline\", \"full_preproc_pca\")\n",
    "\n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"pct_data_removed\", pct_removed)\n",
    "        mlflow.log_metric(\"num_rows_removed\", before - after)\n",
    "        mlflow.log_metric(\"pca_fit_time_sec\", fit_time)\n",
    "        evr = pca_model.explained_variance_ratio_\n",
    "        mlflow.log_metric(\"explained_variance_pc1\", float(evr[0]) if len(evr) > 0 else 0)\n",
    "        mlflow.log_metric(\"explained_variance_total\", float(np.sum(evr)))\n",
    "\n",
    "        # 7) Generate and log artifacts (corr, scatter, scree, etc.)\n",
    "        num_df = df.select_dtypes(include=\"number\").drop(columns=[\"Time\", \"Class\"], errors=\"ignore\")\n",
    "        # Correlation heatmap\n",
    "        plt.figure(figsize=(14,12))\n",
    "        sns.heatmap(num_df.corr(), annot=True, fmt=\".2f\", cmap=\"vlag\")\n",
    "        plt.title(\"Correlation Matrix\")\n",
    "        corr_path = f\"{domino_artifact_dir}/raw_correlation_matrix.png\"\n",
    "        plt.savefig(corr_path); plt.close()\n",
    "        mlflow.log_artifact(corr_path, artifact_path=\"plots\")\n",
    "        # Scatter matrix\n",
    "        sample_df = num_df.sample(n=500, random_state=0)\n",
    "        fig = scatter_matrix(sample_df, alpha=0.2, diagonal=\"hist\", figsize=(15,15))\n",
    "        scatter_path = f\"{domino_artifact_dir}/raw_scatter_plots.png\"\n",
    "        plt.savefig(scatter_path); plt.close()\n",
    "        mlflow.log_artifact(scatter_path, artifact_path=\"plots\")\n",
    "        # Scree and cumulative\n",
    "        evr = pca_model.explained_variance_ratio_\n",
    "        pcs = np.arange(1, len(evr)+1)\n",
    "        # Scree\n",
    "        plt.figure(figsize=(8,5))\n",
    "        plt.plot(pcs, evr, marker='o')\n",
    "        plt.xlabel(\"PC\"); plt.ylabel(\"Explained Var Ratio\"); plt.title(\"Scree Plot\")\n",
    "        scree_path = f\"{domino_artifact_dir}/pca_scree.png\"\n",
    "        plt.savefig(scree_path); plt.close()\n",
    "        mlflow.log_artifact(scree_path, artifact_path=\"plots\")\n",
    "        # Cumulative\n",
    "        cumvar = np.cumsum(evr)\n",
    "        plt.figure(figsize=(8,5))\n",
    "        plt.plot(pcs, cumvar, marker='o')\n",
    "        plt.axhline(0.9, linestyle='--', label='90%')\n",
    "        plt.xlabel(\"# Components\"); plt.ylabel(\"Cumulative Var\"); plt.title(\"Cumulative Variance\")\n",
    "        plt.legend()\n",
    "        cumvar_path = f\"{domino_artifact_dir}/pca_cumulative_variance.png\"\n",
    "        plt.savefig(cumvar_path); plt.close()\n",
    "        mlflow.log_artifact(cumvar_path, artifact_path=\"plots\")\n",
    "\n",
    "        # 8) EDA HTML\n",
    "        profile = ProfileReport(df, title=\"EDA Report\", explorative=True, minimal=True)\n",
    "        eda_path = f\"{domino_artifact_dir}/eda_report.html\"\n",
    "        profile.to_file(eda_path)\n",
    "        mlflow.log_artifact(eda_path, artifact_path=\"eda\")\n",
    "\n",
    "    return df, pca_df\n",
    "\n",
    "# Usage:\n",
    "raw_df, pca_df = run_data_ingestion_and_processing(\n",
    "    raw_filename=\"raw_cc_transactions.csv\",\n",
    "    pca_filename=\"cleaned_cc_transactions.csv\",\n",
    "    n_components=8\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a70c71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
