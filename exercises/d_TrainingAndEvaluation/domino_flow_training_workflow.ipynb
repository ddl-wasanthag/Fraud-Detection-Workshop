{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domino Flow Training and Evaluation Workflow\n",
    "\n",
    "This notebook demonstrates how to execute a Domino Flow for training multiple fraud detection models and registering the best performing model to the Domino Model Registry.\n",
    "\n",
    "## Overview\n",
    "- Execute Domino Flow to train AdaBoost, GaussianNB, and XGBoost classifiers\n",
    "- Monitor execution progress\n",
    "- Compare model performance using Experiment Manager\n",
    "- Register the best model to Model Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Execute Domino Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# Store the flow execution ID for later use\n",
    "flow_execution_id = None\n",
    "experiment_name = None\n",
    "\n",
    "# Execute the Domino Flow\n",
    "print(\"Starting Domino Flow execution...\")\n",
    "try:\n",
    "    # Run the workflow using pyflyte with --remote flag for Domino execution\n",
    "    result = subprocess.run(\n",
    "        [\"pyflyte\", \"run\", \"--remote\", \"exercises/d_TrainingAndEvaluation/workflow.py\", \"credit_card_fraud_detection_workflow\"],\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        cwd=\"/mnt/code\"\n",
    "    )\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"Flow execution started successfully!\")\n",
    "        print(f\"Output: {result.stdout}\")\n",
    "        \n",
    "        # Extract experiment name from the environment or generate it\n",
    "        try:\n",
    "            # Import the domino_short_id function to generate the same experiment name\n",
    "            import sys\n",
    "            sys.path.append('/mnt/code')\n",
    "            from domino_short_id import domino_short_id\n",
    "            experiment_name = f\"CC Fraud Classifier Training {domino_short_id()}\"\n",
    "            print(f\"Flow will create experiments under: {experiment_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not determine experiment name: {e}\")\n",
    "            experiment_name = \"CC Fraud Classifier Training\"\n",
    "        \n",
    "    else:\n",
    "        print(f\"Flow execution failed with return code {result.returncode}\")\n",
    "        print(f\"Error: {result.stderr}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error executing flow: {e}\")\n",
    "    print(\"Note: This may require Domino platform environment setup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: Monitor Flow Execution in Domino UI\n",
    "\n",
    "### Instructions for Viewing Flow Progress:\n",
    "\n",
    "1. **Navigate to Flows Dashboard**\n",
    "   - In the Domino UI, click on \"Flows\" in the left navigation panel\n",
    "   - You should see your \"credit_card_fraud_detection_workflow\" listed\n",
    "\n",
    "2. **Monitor Execution Status**\n",
    "   - Click on the flow name to view the execution details\n",
    "   - Watch the DAG (Directed Acyclic Graph) as tasks complete\n",
    "   - Each task will show status: Running, Completed, or Failed\n",
    "\n",
    "3. **Task Execution Order**\n",
    "   - Three training tasks run in parallel:\n",
    "     - Train AdaBoost classifier\n",
    "     - Train GaussianNB classifier  \n",
    "     - Train XGBoost classifier\n",
    "   - After all training completes, the comparison task executes\n",
    "\n",
    "4. **View Task Logs**\n",
    "   - Click on individual tasks to view their execution logs\n",
    "   - Monitor progress and check for any errors\n",
    "\n",
    "### Expected Flow Duration: 10-15 minutes\n",
    "\n",
    "Wait for all tasks to complete before proceeding to the next step.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Access Experiment Manager and Compare Results\n",
    "\n",
    "### Instructions for Experiment Manager:\n",
    "\n",
    "1. **Open Experiment Manager**\n",
    "   - Click \"Experiment Manager\" in the left navigation panel\n",
    "   - You should see 3 new experiment runs from the flow execution\n",
    "\n",
    "2. **Compare Model Performance**\n",
    "   - Select all 3 runs (AdaBoost, GaussianNB, XGBoost)\n",
    "   - Click \"Compare\" button in the top toolbar\n",
    "\n",
    "3. **Analyze Metrics**\n",
    "   - Review key metrics: ROC-AUC, Precision, Recall, F1-Score\n",
    "   - Look for the model with the highest performance\n",
    "   - Expected best performer: XGBoost\n",
    "\n",
    "4. **Review Model Details**\n",
    "   - Click on the best performing model\n",
    "   - Review complete traceability: code, data, parameters, artifacts\n",
    "   - Check model artifacts and performance visualizations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Register Best Model to Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section demonstrates programmatic model registration\n",
    "# In practice, you would typically do this through the Domino UI as shown in the instructions\n",
    "\n",
    "import mlflow\n",
    "import mlflow.tracking\n",
    "from datetime import datetime\n",
    "\n",
    "def get_best_experiment_run(target_experiment_name=None):\n",
    "    \"\"\"\n",
    "    Retrieve the best performing experiment run based on accuracy from the specified experiment\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if target_experiment_name is None:\n",
    "            target_experiment_name = experiment_name\n",
    "            \n",
    "        if target_experiment_name is None:\n",
    "            print(\"No experiment name specified\")\n",
    "            return None\n",
    "            \n",
    "        print(f\"Searching for best model in experiment: {target_experiment_name}\")\n",
    "        \n",
    "        # Get the specific experiment by name\n",
    "        try:\n",
    "            experiment = mlflow.get_experiment_by_name(target_experiment_name)\n",
    "            if experiment is None:\n",
    "                print(f\"Experiment '{target_experiment_name}' not found\")\n",
    "                # Fall back to searching all experiments\n",
    "                experiments = mlflow.search_experiments()\n",
    "                if not experiments:\n",
    "                    print(\"No experiments found\")\n",
    "                    return None\n",
    "                experiment_ids = [exp.experiment_id for exp in experiments]\n",
    "            else:\n",
    "                experiment_ids = [experiment.experiment_id]\n",
    "                print(f\"Found experiment: {experiment.name} (ID: {experiment.experiment_id})\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error finding experiment: {e}\")\n",
    "            # Fall back to all experiments\n",
    "            experiments = mlflow.search_experiments()\n",
    "            experiment_ids = [exp.experiment_id for exp in experiments] if experiments else []\n",
    "        \n",
    "        if not experiment_ids:\n",
    "            print(\"No experiments available\")\n",
    "            return None\n",
    "        \n",
    "        # Search for runs with accuracy metrics, ordered by accuracy (best first)\n",
    "        runs = mlflow.search_runs(\n",
    "            experiment_ids=experiment_ids,\n",
    "            filter_string=\"metrics.accuracy > 0\",\n",
    "            order_by=[\"metrics.accuracy DESC\"],\n",
    "            max_results=10\n",
    "        )\n",
    "        \n",
    "        if runs.empty:\n",
    "            print(\"No runs found with accuracy metrics in the target experiment\")\n",
    "            return None\n",
    "        \n",
    "        # Get the best performing run\n",
    "        best_run = runs.iloc[0]\n",
    "        \n",
    "        print(f\"Best model found:\")\n",
    "        print(f\"  Run ID: {best_run['run_id']}\")\n",
    "        print(f\"  Experiment: {best_run.get('experiment_id', 'Unknown')}\")\n",
    "        print(f\"  Model: {best_run.get('tags.model_type', 'Unknown')}\")\n",
    "        print(f\"  Accuracy: {best_run['metrics.accuracy']:.4f}\")\n",
    "        print(f\"  ROC-AUC: {best_run.get('metrics.roc_auc', 'N/A')}\")\n",
    "        print(f\"  Precision: {best_run.get('metrics.precision_fraud', 'N/A')}\")\n",
    "        print(f\"  Recall: {best_run.get('metrics.recall_fraud', 'N/A')}\")\n",
    "        print(f\"  F1-Score: {best_run.get('metrics.f1_fraud', 'N/A')}\")\n",
    "        \n",
    "        return best_run\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving experiments: {e}\")\n",
    "        return None\n",
    "\n",
    "# Get the best performing model from the current flow's experiment\n",
    "best_run = get_best_experiment_run(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_model_to_registry(run_info, model_name=\"fraud_detection_classifier\"):\n",
    "    \"\"\"\n",
    "    Register the best model to Domino Model Registry with model card and specifications\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if run_info is None:\n",
    "            print(\"No run information provided\")\n",
    "            return None\n",
    "            \n",
    "        run_id = run_info['run_id']\n",
    "        model_uri = f\"runs:/{run_id}/model\"\n",
    "        \n",
    "        # Create model version with only required parameters\n",
    "        model_version = mlflow.register_model(\n",
    "            model_uri=model_uri,\n",
    "            name=model_name\n",
    "        )\n",
    "        \n",
    "        print(f\"Model registered successfully:\")\n",
    "        print(f\"  Name: {model_version.name}\")\n",
    "        print(f\"  Version: {model_version.version}\")\n",
    "        print(f\"  Run ID: {run_id}\")\n",
    "        print(f\"  Model URI: {model_uri}\")\n",
    "        \n",
    "        # Check dataset information used by Flow scripts\n",
    "        dataset_info, data_files = check_flow_datasets()\n",
    "        \n",
    "        # Print first 3 data files found\n",
    "        if data_files:\n",
    "            print(f\"📁 Data files used: {', '.join(data_files[:3])}\")\n",
    "            if len(data_files) > 3:\n",
    "                print(f\"   ... and {len(data_files) - 3} more files\")\n",
    "        \n",
    "        # Extract training framework from model type or tags - enhanced detection\n",
    "        training_framework = None\n",
    "        \n",
    "        # Debug: Print available run info for troubleshooting\n",
    "        print(f\"🔍 Debug - Available run tags:\")\n",
    "        for key in run_info.keys():\n",
    "            if key.startswith('tags.'):\n",
    "                print(f\"   {key}: {run_info[key]}\")\n",
    "        \n",
    "        # Try multiple methods to detect framework\n",
    "        methods = [\n",
    "            ('tags.model_type', run_info.get('tags.model_type')),\n",
    "            ('tags.mlflow.runName', run_info.get('tags.mlflow.runName', '')),\n",
    "            ('tags.model_name', run_info.get('tags.model_name')),\n",
    "            ('tags.algorithm', run_info.get('tags.algorithm')),\n",
    "        ]\n",
    "        \n",
    "        for method, value in methods:\n",
    "            if value and training_framework is None:\n",
    "                value_lower = str(value).lower()\n",
    "                if 'xgb' in value_lower or 'xgboost' in value_lower:\n",
    "                    training_framework = 'XGBoost'\n",
    "                    print(f\"✅ Detected XGBoost from {method}: {value}\")\n",
    "                    break\n",
    "                elif 'ada' in value_lower or 'adaboost' in value_lower:\n",
    "                    training_framework = 'AdaBoost'\n",
    "                    print(f\"✅ Detected AdaBoost from {method}: {value}\")\n",
    "                    break\n",
    "                elif 'gnb' in value_lower or 'gaussian' in value_lower or 'naive' in value_lower:\n",
    "                    training_framework = 'GaussianNB'\n",
    "                    print(f\"✅ Detected GaussianNB from {method}: {value}\")\n",
    "                    break\n",
    "        \n",
    "        # Fallback if no detection worked\n",
    "        if training_framework is None:\n",
    "            training_framework = 'Unknown Classifier'\n",
    "            print(f\"⚠️ Could not detect training framework, using fallback: {training_framework}\")\n",
    "        \n",
    "        # Update model with comprehensive card template and specifications\n",
    "        client = mlflow.tracking.MlflowClient()\n",
    "        \n",
    "        # Set simple one-sentence description for model version\n",
    "        desc = \"Best performing fraud detection classifier based on accuracy from automated flow training\"\n",
    "        client.update_model_version(\n",
    "            name=model_name,\n",
    "            version=model_version.version,\n",
    "            description=desc\n",
    "        )\n",
    "        \n",
    "        # Set basic model tags using client\n",
    "        basic_tags = {\n",
    "            \"model_type\": run_info.get('tags.model_type', 'classifier'),\n",
    "            \"use_case\": \"fraud_detection\",\n",
    "            \"training_data\": \"credit_card_transactions\",\n",
    "            \"performance_metric\": \"accuracy\",\n",
    "            \"deployment_ready\": \"true\"\n",
    "        }\n",
    "        \n",
    "        for key, value in basic_tags.items():\n",
    "            client.set_model_version_tag(model_name, model_version.version, key, value)\n",
    "        \n",
    "        # Check if model card template exists and use it for registered model description\n",
    "        template_path = \"/mnt/code/exercises/d_TrainingAndEvaluation/Model_Registry_template.md\"\n",
    "        try:\n",
    "            with open(template_path, 'r') as file:\n",
    "                model_card_description = file.read()\n",
    "                client.update_registered_model(model_name, model_card_description)\n",
    "                print(f\"✅ Updated model description from template: {template_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Could not load model card template: {e}\")\n",
    "            # Fallback to simple description\n",
    "            fallback_desc = \"Fraud Detection Classifier trained using Domino Flow with multiple algorithm comparison\"\n",
    "            client.update_registered_model(model_name, fallback_desc)\n",
    "        \n",
    "        # Estimate model artifacts size (could check actual files if available)\n",
    "        try:\n",
    "            # Try to get actual model size if artifacts are accessible\n",
    "            import os\n",
    "            artifacts_path = f\"/tmp/mlruns/{run_info.get('experiment_id', '')}/{run_id}/artifacts/model\"\n",
    "            if os.path.exists(artifacts_path):\n",
    "                total_size = sum(os.path.getsize(os.path.join(artifacts_path, f)) \n",
    "                               for f in os.listdir(artifacts_path) if os.path.isfile(os.path.join(artifacts_path, f)))\n",
    "                model_size = f\"{total_size / (1024*1024):.1f} MB\"\n",
    "            else:\n",
    "                # Use reasonable estimates based on model type\n",
    "                size_estimates = {\n",
    "                    'XGBoost': '15-25 MB',\n",
    "                    'AdaBoost': '8-15 MB', \n",
    "                    'GaussianNB': '< 5 MB'\n",
    "                }\n",
    "                model_size = size_estimates.get(training_framework, '10-20 MB')\n",
    "        except:\n",
    "            model_size = '10-20 MB (estimated)'\n",
    "        \n",
    "        # Estimate inference memory requirements based on model type\n",
    "        memory_estimates = {\n",
    "            'XGBoost': '512 MB - 1 GB (tree ensemble requires memory for all trees)',\n",
    "            'AdaBoost': '256 MB - 512 MB (smaller ensemble, moderate memory)',\n",
    "            'GaussianNB': '128 MB - 256 MB (simple probabilistic model, minimal memory)'\n",
    "        }\n",
    "        inference_memory = memory_estimates.get(training_framework, '256 MB - 512 MB (estimated)')\n",
    "        \n",
    "        # Set relevant model specifications - ensure framework is properly set\n",
    "        model_specs = {\n",
    "            # Core model specifications\n",
    "            \"mlflow.domino.specs.Training Framework\": training_framework,\n",
    "            \"mlflow.domino.specs.Model Artifacts Size\": model_size,\n",
    "            \"mlflow.domino.specs.Training Dataset Size\": dataset_info,\n",
    "            \"mlflow.domino.specs.Inference Memory\": inference_memory\n",
    "        }\n",
    "        \n",
    "        print(f\"🔧 Setting model specs:\")\n",
    "        for key, value in model_specs.items():\n",
    "            print(f\"   {key}: {value}\")\n",
    "        \n",
    "        # Apply all model specifications\n",
    "        for key, value in model_specs.items():\n",
    "            try:\n",
    "                client.set_registered_model_tag(model_name, key, value)\n",
    "                print(f\"✅ Set spec: {key}\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Failed to set spec {key}: {e}\")\n",
    "        \n",
    "        print(f\"✅ Applied {len(basic_tags)} basic tags and {len(model_specs)} model specifications\")\n",
    "        print(f\"   Training Framework: {training_framework}\")\n",
    "        print(f\"   Model Size: {model_size}\")\n",
    "        print(f\"   Dataset Info: {dataset_info}\")\n",
    "        print(f\"   Inference Memory: {inference_memory}\")\n",
    "        print(\"Model registration completed with full model card and specifications\")\n",
    "        \n",
    "        return model_version\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error registering model: {e}\")\n",
    "        return None\n",
    "\n",
    "def check_flow_datasets():\n",
    "    \"\"\"\n",
    "    Check dataset information used by Flow scripts - fast file-based check\n",
    "    Returns dataset info and list of data files found\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import os\n",
    "        data_files_found = []\n",
    "        \n",
    "        # Primary dataset file used by all trainers\n",
    "        dataset_filename = 'transformed_cc_transactions.csv'\n",
    "        \n",
    "        # Check multiple possible locations for datasets\n",
    "        search_paths = [\n",
    "            \"/mnt/data/Fraud-Detection-Workshop/\",  # Domino dataset path\n",
    "            \"/mnt/code/\",  # Local code directory\n",
    "            \"/tmp/\",  # Temp directory\n",
    "        ]\n",
    "        \n",
    "        # Look for CSV files in each path\n",
    "        for search_path in search_paths:\n",
    "            if os.path.exists(search_path):\n",
    "                try:\n",
    "                    files = [f for f in os.listdir(search_path) \n",
    "                           if f.endswith('.csv') and os.path.isfile(os.path.join(search_path, f))]\n",
    "                    for file in files:\n",
    "                        if file not in data_files_found:  # Avoid duplicates\n",
    "                            data_files_found.append(file)\n",
    "                except Exception:\n",
    "                    continue\n",
    "        \n",
    "        # Try to get info from the main dataset file\n",
    "        dataset_info = \"~500,000 credit card transactions (estimated)\"\n",
    "        for search_path in search_paths:\n",
    "            dataset_path = os.path.join(search_path, dataset_filename)\n",
    "            if os.path.exists(dataset_path):\n",
    "                try:\n",
    "                    # Quick file size check (fastest)\n",
    "                    file_size_mb = os.path.getsize(dataset_path) / (1024 * 1024)\n",
    "                    \n",
    "                    # Quick row count check (read just first few lines to estimate)\n",
    "                    with open(dataset_path, 'r') as f:\n",
    "                        first_line = f.readline()  # header\n",
    "                        line_count = 1\n",
    "                        for _ in range(100):  # sample first 100 rows\n",
    "                            if f.readline():\n",
    "                                line_count += 1\n",
    "                            else:\n",
    "                                break\n",
    "                        \n",
    "                        # Estimate total rows based on file size ratio\n",
    "                        sample_size = f.tell()\n",
    "                        if sample_size > 0:\n",
    "                            estimated_rows = int((file_size_mb * 1024 * 1024) / sample_size * line_count)\n",
    "                        else:\n",
    "                            estimated_rows = line_count\n",
    "                    \n",
    "                    dataset_info = f\"{estimated_rows:,} transactions ({file_size_mb:.1f} MB)\"\n",
    "                    break\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    dataset_info = f\"Dataset found but could not read: {dataset_filename} ({file_size_mb:.1f} MB)\"\n",
    "                    break\n",
    "        \n",
    "        return dataset_info, data_files_found\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not check dataset info: {e}\")\n",
    "        return \"~500,000 credit card transactions (estimated)\", []\n",
    "\n",
    "# Register the best model\n",
    "if best_run is not None:\n",
    "    registered_model = register_model_to_registry(best_run)\n",
    "else:\n",
    "    print(\"No best run available for registration\")\n",
    "    print(\"Please use the Domino UI to manually register the model as described in the instructions\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "def register_preprocessing_pipeline():\n    \"\"\"\n    Register the preprocessing pipeline from Exercise 3 as a separate model endpoint.\n    This creates the feature scaling endpoint needed by the Streamlit app.\n    \"\"\"\n    import sys\n    import os\n    \n    # Add project root to path to import from Exercise 3\n    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n    if project_root not in sys.path:\n        sys.path.insert(0, project_root)\n    \n    try:\n        # Import the preprocessing functions from Exercise 3\n        from exercises.c_DataEngineering.data_engineering import add_derived_features\n        \n        # Look for existing preprocessing experiments\n        preprocessing_experiments = mlflow.search_experiments(\n            filter_string=\"name LIKE '%Preprocessing%'\"\n        )\n        \n        if preprocessing_experiments:\n            # Get the most recent preprocessing experiment\n            latest_experiment = max(preprocessing_experiments, \n                                  key=lambda x: x.creation_time)\n            \n            print(f\"Found preprocessing experiment: {latest_experiment.name}\")\n            \n            # Search for preprocessing runs in this experiment\n            preprocessing_runs = mlflow.search_runs(\n                experiment_ids=[latest_experiment.experiment_id],\n                filter_string=\"tags.pipeline = 'preprocessing'\",\n                order_by=[\"start_time DESC\"],\n                max_results=1\n            )\n            \n            if not preprocessing_runs.empty:\n                best_preprocessing_run = preprocessing_runs.iloc[0]\n                run_id = best_preprocessing_run.run_id\n                \n                print(f\"Found preprocessing run: {run_id}\")\n                \n                # Register the preprocessing pipeline as a model\n                preprocessing_model_uri = f\"runs:/{run_id}/preprocessing_pipeline\"\n                \n                try:\n                    # Register the preprocessing pipeline\n                    registered_model = mlflow.register_model(\n                        model_uri=preprocessing_model_uri,\n                        name=\"CC_Fraud_Feature_Scaling\"\n                    )\n                    \n                    print(f\"✅ Registered preprocessing pipeline as model: CC_Fraud_Feature_Scaling\")\n                    print(f\"   Model Version: {registered_model.version}\")\n                    \n                    # Update model version with description and tags\n                    client = mlflow.tracking.MlflowClient()\n                    \n                    # Add description\n                    client.update_model_version(\n                        name=\"CC_Fraud_Feature_Scaling\",\n                        version=registered_model.version,\n                        description=\"Feature scaling pipeline for credit card fraud detection preprocessing\"\n                    )\n                    \n                    # Add tags\n                    client.set_model_version_tag(\n                        name=\"CC_Fraud_Feature_Scaling\",\n                        version=registered_model.version,\n                        key=\"stage\",\n                        value=\"staging\"\n                    )\n                    \n                    client.set_model_version_tag(\n                        name=\"CC_Fraud_Feature_Scaling\",\n                        version=registered_model.version,\n                        key=\"model_type\",\n                        value=\"preprocessing\"\n                    )\n                    \n                    print(f\"✅ Updated model version with description and tags\")\n                    \n                    return registered_model\n                    \n                except Exception as e:\n                    print(f\"❌ Error registering preprocessing model: {e}\")\n                    return None\n            else:\n                print(\"❌ No preprocessing runs found with 'preprocessing' tag\")\n                return None\n        else:\n            print(\"❌ No preprocessing experiments found\")\n            print(\"   Please run Exercise 3 (Data Engineering) first to create the preprocessing pipeline\")\n            return None\n            \n    except ImportError as e:\n        print(f\"❌ Could not import from Exercise 3: {e}\")\n        print(\"   Please ensure Exercise 3 (Data Engineering) has been completed\")\n        return None\n\n# Register the preprocessing pipeline\nprint(\"🔄 Registering preprocessing pipeline as feature scaling endpoint...\")\npreprocessing_model = register_preprocessing_pipeline()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Model Registration Instructions\n",
    "\n",
    "### If programmatic registration is not available, follow these steps in the Domino UI:\n",
    "\n",
    "1. **Select Best Model in Experiment Manager**\n",
    "   - Choose the run with highest ROC-AUC (typically XGBoost)\n",
    "   - Click on the run to view details\n",
    "\n",
    "2. **Register Model**\n",
    "   - Click \"Register Model From Run\" in the upper right corner\n",
    "   - Enter model name: `fraud_detection_classifier_v1`\n",
    "\n",
    "3. **Add Model Metadata**\n",
    "   - Description: \"Production-ready fraud detection classifier\"\n",
    "   - Tags: Use the template from `Model_Registry_template.md`\n",
    "   - Model specifications: Define input/output schemas\n",
    "\n",
    "4. **Governance and Approval**\n",
    "   - Review governance requirements\n",
    "   - Submit for approval if required by your organization\n",
    "   - Set deployment stage (Staging/Production)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the complete Domino Flow workflow for:\n",
    "\n",
    "1. **Flow Execution**: Running parallel model training tasks\n",
    "2. **Monitoring**: Tracking progress through Domino UI\n",
    "3. **Comparison**: Evaluating model performance in Experiment Manager\n",
    "4. **Registration**: Adding the best model to Model Registry\n",
    "\n",
    "### Key Domino Concepts Utilized:\n",
    "- **Domino Flows**: Visual workflow orchestration for ML pipelines\n",
    "- **Experiment Manager**: Centralized tracking and comparison of model runs\n",
    "- **Model Registry**: Cataloging and governance for production models\n",
    "\n",
    "### Next Steps:\n",
    "- Model deployment via REST API endpoints\n",
    "- Integration with Streamlit application\n",
    "- Production monitoring and governance\n",
    "\n",
    "This completes the **Training and Evaluation** phase of the fraud detection workshop."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}