# Fraud Detection Workshop

This workshop provides hands-on experience with the Domino Data Lab platform while completing the full model development and delivery lifecycle, from data preparation through model deployment.

---

## Workshop Overview

The following exercises are designed to be completed sequentially. Each exercise directory contains all necessary resources including instructions, notebooks, and scripts.

### Exercise 1: Platform Setup
Project initialization, team collaboration setup, and governance workflow approval.

**Instructions:** [Up and Running Guide](exercises/a_UpAndRunning/Instructions%20-%20Up%20and%20Running.md)  
**Relevant Documentation:** [Start a Jupyter Workspace](https://docs.dominodatalab.com/en/latest/user_guide/93aef2/start-a-jupyter-workspace/)

---

### Exercise 2: Data Exploration
Interactive data analysis using Jupyter notebooks. Import transaction data, perform data cleaning, generate visualizations, and save processed datasets.

**Instructions:** [Data Exploration Guide](exercises/b_DataExploration/Instructions%20-%20Data%20Exploration.md)  
**Relevant Documentation:** [Set up Jupyter AI in Jupyter environment](https://docs.dominodatalab.com/en/cloud/user_guide/1f4149/set-up-jupyter-ai-in-jupyter-environment/)

---

### Exercise 3: Data Engineering
Automated data processing pipeline using batch jobs. Apply feature engineering, data normalization, and scaling transformations. Generate versioned datasets and preprocessing models.

**Instructions:** [Data Engineering Guide](exercises/c_DataEngineering/Instructions%20-%20Data%20Engineering.md)  
**Relevant Documentation:** [Create and run Jobs](https://docs.dominodatalab.com/en/latest/user_guide/af97b7/create-and-run-jobs/)

---

### Exercise 4: Model Training and Evaluation
Orchestrated model training using Domino Flows. Execute parallel training workflows for multiple algorithms, compare performance metrics, and register optimal models for deployment.

**Instructions:** [Training and Evaluation Guide](exercises/d_TrainingAndEvaluation/Instructions%20-%20Training%20And%20Evaluation.md)  
**Relevant Documentation:** [Define Flows](https://docs.dominodatalab.com/en/latest/user_guide/e09156/define-flows/) | [Develop and deploy ML pipelines](https://docs.dominodatalab.com/en/cloud/user_guide/d03252/develop-and-deploy-ml-pipelines/)

---

### Exercise 5: Model Deployment
Production model deployment through multiple channels:
- REST API endpoints
- Interactive web applications  
- Automated launchers

**Instructions:** [Hosting and Execution Guide](exercises/e_HostingAndExecution/Instructions%20-%20HostingAndExecution.md)  
**Relevant Documentation:** [Deploy your Python model](https://docs.dominodatalab.com/en/latest/user_guide/9f10c9/deploy-your-python-model/)

'''
data exploration is a notebook
data engineering and scaling is a normal script
the training is a flow



'''
